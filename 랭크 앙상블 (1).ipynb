{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFb6DCy8Accg"
   },
   "source": [
    "# fold-rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekSIC0vqtUSY"
   },
   "source": [
    "## GPU 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "b3vl1K_9s9of"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyTorch GPU 사용 가능: True\n",
      "✅ LightGBM GPU 지원 여부: /home/ubuntu/.local/lib/python3.12/site-packages/lightgbm/__init__.py\n",
      "✅ XGBoost GPU 지원 여부: 3.0.0\n",
      "✅ CatBoost 버전: 1.2.7\n"
     ]
    }
   ],
   "source": [
    "# ✅ GPU 사용 가능 여부 확인\n",
    "import torch\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost\n",
    "\n",
    "# 모델 임포트 변경\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "print(\"✅ PyTorch GPU 사용 가능:\", torch.cuda.is_available())\n",
    "print(\"✅ LightGBM GPU 지원 여부:\", lgb.__file__)\n",
    "print(\"✅ XGBoost GPU 지원 여부:\", xgb.__version__)\n",
    "print(\"✅ CatBoost 버전:\", catboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYX0fMJJEYhC"
   },
   "source": [
    "## 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8u7z4AxNsxEI"
   },
   "outputs": [],
   "source": [
    "# ✅ 라이브러리 import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tEjPWAl8tQO1"
   },
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "sd=42\n",
    "random.seed(sd)\n",
    "np.random.seed(sd)\n",
    "os.environ['PYTHONHASHSEED'] = str(sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NC0bYFBtWL8"
   },
   "source": [
    "## 데이터 preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_Pw7gqVHtYD9"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "submission_df = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[(train_df['임신 성공 확률'] <= 0.05) | (train_df['임신 성공 확률'] >= 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lQHIv8cIWxuJ"
   },
   "outputs": [],
   "source": [
    "# ID 분리\n",
    "test_ids = test_df['ID']  # ID 컬럼 따로 저장\n",
    "train_df.drop(columns=['ID'], inplace=True)\n",
    "test_df.drop(columns=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3Ou8ctvrRt1W"
   },
   "outputs": [],
   "source": [
    "# 난자 출처 알 수 없음 -> 본인제공 replace\n",
    "train_df['난자 출처'] = train_df['난자 출처'].replace('알 수 없음', '본인 제공')\n",
    "test_df['난자 출처'] = test_df['난자 출처'].replace('알 수 없음', '본인 제공')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unknown\n",
    "train_df['세부 시술 유형'] = train_df['세부 시술 유형'].fillna('Unknown')\n",
    "test_df['세부 시술 유형'] = test_df['세부 시술 유형'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터\n",
    "train_df.loc[(train_df['미세주입(ICSI) 배아 이식 수'].isna()) & (train_df['시술 유형'] == 'DI'), '미세주입(ICSI) 배아 이식 수'] = 0\n",
    "train_df.loc[(train_df['미세주입(ICSI) 배아 이식 수'].isna()) & (train_df['시술 유형'] != 'DI'), '미세주입(ICSI) 배아 이식 수'] = -1\n",
    "\n",
    "# test 데이터\n",
    "test_df.loc[(test_df['미세주입(ICSI) 배아 이식 수'].isna()) & (test_df['시술 유형'] == 'DI'), '미세주입(ICSI) 배아 이식 수'] = 0\n",
    "test_df.loc[(test_df['미세주입(ICSI) 배아 이식 수'].isna()) & (test_df['시술 유형'] != 'DI'), '미세주입(ICSI) 배아 이식 수'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IVF가 아닌 DI의 경우 결측치 대체\n",
    "# 설문 조사에서 DI의 경우 대답할 필요가 없는 항목들이 결측치로 들어간 듯\n",
    "columns_to_update = ['총 생성 배아 수', '이식된 배아 수', '저장된 배아 수',\n",
    "                    '채취된 신선 난자 수', '수정 시도된 난자 수']\n",
    "\n",
    "# train_df 처리\n",
    "for column in columns_to_update:\n",
    "    if train_df[column].dtype == 'object':\n",
    "        # object 타입이면 'Not Answer(DI)'로 채우기\n",
    "        train_df[column] = train_df[column].fillna('Not Answer(DI)')\n",
    "    elif train_df[column].dtype in ['float64', 'int64']:\n",
    "        # 숫자 타입이면 0로 채우기\n",
    "        train_df[column] = train_df[column].fillna(0)\n",
    "\n",
    "# test_df 처리\n",
    "for column in columns_to_update:\n",
    "    if test_df[column].dtype == 'object':\n",
    "        # object 타입이면 'Not Answer(DI)'로 채우기\n",
    "        test_df[column] = test_df[column].fillna('Not Answer(DI)')\n",
    "    elif test_df[column].dtype in ['float64', 'int64']:\n",
    "        # 숫자 타입이면 0로 채우기\n",
    "        test_df[column] = test_df[column].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qRk4kWkXtqy-"
   },
   "outputs": [],
   "source": [
    "# 경과일 대체\n",
    "d_col = ['배아 이식 후 경과일']\n",
    "train_df[d_col] = train_df[d_col].fillna(999)\n",
    "test_df[d_col] = test_df[d_col].fillna(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 횟수 결측치\n",
    "cnt_col  = ['이전 총 임신 횟수',  '이전 총 임신 성공 횟수']\n",
    "\n",
    "train_df[cnt_col] = train_df[cnt_col].fillna('0회')\n",
    "test_df[cnt_col] = test_df[cnt_col].fillna('0회')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mG0F8jD-0Y_r"
   },
   "outputs": [],
   "source": [
    "# 횟수, 회 타입 변경\n",
    "int_col = [ '이전 IVF 시술 횟수', '이전 DI 시술 횟수',\n",
    "           '이전 총 임신 횟수',  '이전 총 임신 성공 횟수']\n",
    "    \n",
    "for col in int_col:\n",
    "    train_df[col] = train_df[col].astype(str).str.extract('(\\d+)').astype(int)\n",
    "    test_df[col] = test_df[col].astype(str).str.extract('(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3_nlqT8yYP6A"
   },
   "outputs": [],
   "source": [
    "# 조건 : 난자 출처 == \"본인 제공\" → 난자 기증자 나이를 시술 당시 나이로 설정\n",
    "condition2 = (train_df['난자 출처'] == \"본인 제공\")\n",
    "train_df.loc[condition2, '난자 기증자 나이'] = train_df.loc[condition2, '환자 시술 당시 나이']\n",
    "\n",
    "condition2_t = (test_df['난자 출처'] == \"본인 제공\")\n",
    "test_df.loc[condition2_t, '난자 기증자 나이'] = test_df.loc[condition2_t, '환자 시술 당시 나이']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbaYqDtfTDSf"
   },
   "source": [
    "## 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FgvDx4yAsZRJ"
   },
   "outputs": [],
   "source": [
    "# 키워드 리스트 정의\n",
    "unique_types = ['ICSI', 'IVF', 'Unknown', 'IUI', 'FER',\n",
    "                'BLASTOCYST', 'AH']\n",
    "\n",
    "# 각 키워드에 대해 새로운 컬럼 생성\n",
    "for keyword in unique_types:\n",
    "    train_df[keyword] = train_df['세부 시술 유형'].str.count(keyword)\n",
    "    test_df[keyword] = test_df['세부 시술 유형'].str.count(keyword)\n",
    "\n",
    "# 기존 col drop\n",
    "train_df.drop('세부 시술 유형', axis=1, inplace=True)\n",
    "test_df.drop('세부 시술 유형', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yc9yFNDclK9K"
   },
   "source": [
    "## 파생변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pjanWP8UlTab"
   },
   "outputs": [],
   "source": [
    "# 임신을 했는데 출산을 못한경우 = 유산\n",
    "train_df['유산 횟수'] = train_df['이전 총 임신 횟수'] - train_df['이전 총 임신 성공 횟수']\n",
    "test_df['유산 횟수'] = test_df['이전 총 임신 횟수'] - test_df['이전 총 임신 성공 횟수']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tPnELKFWsm4E"
   },
   "outputs": [],
   "source": [
    "# 미세주입(ICSI) 아닌 IVF\n",
    "train_df['미세주입이 아닌 배아 이식 수'] = train_df['이식된 배아 수'] - train_df['미세주입(ICSI) 배아 이식 수']\n",
    "test_df['미세주입이 아닌 배아 이식 수'] = test_df['이식된 배아 수'] - test_df['미세주입(ICSI) 배아 이식 수']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gw0lDqn8vMVr"
   },
   "source": [
    "## 배아 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6cNQKPjEe9uH"
   },
   "outputs": [],
   "source": [
    "# 단일 배아를 이식한 경우의 이식된 배아 수가 1이면 성공률이 더 높음\n",
    "train_df.loc[(train_df['단일 배아 이식 여부'] == 1) & (train_df['이식된 배아 수'] == 1), '이식된 배아 수'] = 1.5\n",
    "test_df.loc[(test_df['단일 배아 이식 여부'] == 1) & (test_df['이식된 배아 수'] == 1), '이식된 배아 수'] = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6vRQhP4k6f9v"
   },
   "outputs": [],
   "source": [
    "# 이식 배아 수/ 나이\n",
    "# 나이 재 정의\n",
    "age_bin_mapping = {\n",
    "    \"만18-34세\": 1,\n",
    "    \"만35-37세\": 2,\n",
    "    \"만38-39세\": 3,\n",
    "    \"만40-42세\": 4,\n",
    "    \"만43-44세\": 5,\n",
    "    \"만45-50세\": 6,\n",
    "    \"알 수 없음\": 7\n",
    "}\n",
    "\n",
    "# 나이  적용\n",
    "train_df['나이'] = train_df['환자 시술 당시 나이'].map(age_bin_mapping)\n",
    "test_df['나이'] = test_df['환자 시술 당시 나이'].map(age_bin_mapping)\n",
    "\n",
    "# 나이 별 배아수\n",
    "train_df['이식 배아 수/나이'] = train_df['이식된 배아 수'] / train_df['나이']\n",
    "\n",
    "test_df['이식 배아 수/나이'] = test_df['이식된 배아 수'] / test_df['나이']\n",
    "\n",
    "# 나이 drop\n",
    "train_df.drop('나이', axis=1, inplace=True)\n",
    "test_df.drop('나이', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqCaMRG-Lwqd"
   },
   "source": [
    "## 범주형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aqwQBG-BYaZx"
   },
   "outputs": [],
   "source": [
    "# categorical로 바꿔줌\n",
    "cat_col = ['배란 자극 시술 여부', '단일 배아 이식 여부', '불임 원인 - 난관 질환', '불임 원인 - 배란 장애', \n",
    "           '불임 원인 - 남성 요인', '불임 원인 - 자궁내막증', '불임 원인 - 불명확', '해동 난자 사용 여부', \n",
    "           '신선 난자 사용 여부', '동결 배아 사용 여부', '신선 배아 사용 여부','기증 배아 사용 여부', \n",
    "           '착상 전 PGD 시행 여부', '착상 전 PGS 시행 여부', 'ICSI', 'IVF', 'Unknown', 'IUI', 'BLASTOCYST',     \n",
    "           'AH','FER', '유산 횟수']\n",
    "\n",
    "for col in cat_col:\n",
    "    train_df[col] = train_df[col].astype(str)\n",
    "    test_df[col] = test_df[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VTWPML9IjARY"
   },
   "outputs": [],
   "source": [
    "# 범주형 변수 지정\n",
    "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# 범주형 변수를 category 타입으로 변환\n",
    "for col in categorical_features:\n",
    "    train_df[col] = train_df[col].astype(\"category\")\n",
    "    test_df[col] = test_df[col].astype(\"category\")  # 테스트 데이터도 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wH-MYX8HDbUv"
   },
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sqoVpjjxbC27"
   },
   "outputs": [],
   "source": [
    "# 타겟 분리\n",
    "y_train = train_df['임신 성공 확률']\n",
    "X_train = train_df.drop(columns=['임신 성공 확률'])\n",
    "X_test = test_df.copy()\n",
    "\n",
    "# KFold 정의\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=sd)\n",
    "\n",
    "# params \n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'random_state': sd,\n",
    "    'device': 'gpu'\n",
    "}\n",
    "\n",
    "# CatBoost\n",
    "cat_params = {\n",
    "    'loss_function': 'RMSE',\n",
    "    'learning_rate': 0.1,\n",
    "    'iterations': 1000,\n",
    "    'depth': 6,\n",
    "    'random_seed': sd,\n",
    "    'od_wait': 100,\n",
    "    'task_type': 'GPU',\n",
    "    'verbose': 200,\n",
    "}\n",
    "\n",
    "# XGBoost\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 1000,\n",
    "    'random_state': sd,\n",
    "    'tree_method': 'gpu_hist'\n",
    "}\n",
    "\n",
    "# 모델별 데이터 준비\n",
    "models_dict = {'lgbm': [], 'xgb': [], 'cat': []}\n",
    "preds_dict = {'lgbm': [], 'xgb': [], 'cat': []}\n",
    "scores_dict = {'lgbm': [], 'xgb': [], 'cat': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "cmMaYEk6W4GC"
   },
   "outputs": [],
   "source": [
    "# 각 모델에서 드롭할 컬럼 지정\n",
    "# LGBM에서는 drop하지 않는다\n",
    "drop_features = {\n",
    "    'lgbm': ['이전 총 임신 성공 횟수', 'BLASTOCYST', \n",
    "             '신선 배아 사용 여부','이전 IVF 시술 횟수'],\n",
    "    'xgb': ['난자 출처'],\n",
    "    'cat': []\n",
    "}\n",
    "\n",
    "# 모델별 데이터 준비\n",
    "def prepare_model_data(model_name, X_train, X_test):\n",
    "    X_train_model = X_train.drop(columns=drop_features[model_name])\n",
    "    X_test_model = X_test.drop(columns=drop_features[model_name])\n",
    "    categorical_features_model = [col for col in categorical_features if col not in drop_features[model_name]]\n",
    "    return X_train_model, X_test_model, categorical_features_model\n",
    "\n",
    "# LGBM 데이터 준비\n",
    "X_train_lgbm, X_test_lgbm, categorical_features_lgbm = prepare_model_data('lgbm', X_train, X_test)\n",
    "# XGBoost 데이터 준비\n",
    "X_train_xgb, X_test_xgb, categorical_features_xgb = prepare_model_data('xgb', X_train, X_test)\n",
    "# CatBoost 데이터 준비\n",
    "X_train_cat, X_test_cat, categorical_features_cat = prepare_model_data('cat', X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14631,
     "status": "ok",
     "timestamp": 1743670554704,
     "user": {
      "displayName": "이승현",
      "userId": "09131068715081423692"
     },
     "user_tz": -540
    },
    "id": "4tnJ5WlFm41W",
    "outputId": "7880f303-8b21-4a08-a795-b17b67c9d7cf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 90428, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA A10, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.69 MB) transferred to GPU in 0.003134 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.245295\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.401239\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[91]\tvalid_0's rmse: 0.401171\n",
      "[LGBM] Fold 1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 188\n",
      "[LightGBM] [Info] Number of data points in the train set: 90429, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA A10, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.69 MB) transferred to GPU in 0.002341 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.246054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.399888\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[43]\tvalid_0's rmse: 0.399543\n",
      "[LGBM] Fold 2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 90429, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA A10, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.69 MB) transferred to GPU in 0.002512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.245712\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.399043\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[64]\tvalid_0's rmse: 0.398993\n",
      "[LGBM] Fold 3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 189\n",
      "[LightGBM] [Info] Number of data points in the train set: 90429, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA A10, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (1.03 MB) transferred to GPU in 0.003802 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.245446\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.40099\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[48]\tvalid_0's rmse: 0.400876\n",
      "[LGBM] Fold 4\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 190\n",
      "[LightGBM] [Info] Number of data points in the train set: 90429, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA A10, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (1.03 MB) transferred to GPU in 0.003831 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.246864\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.398029\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[54]\tvalid_0's rmse: 0.397839\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "# LGBM 학습\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train_lgbm)):\n",
    "    print(f\"[LGBM] Fold {fold}\")\n",
    "    X_tr, X_val = X_train_lgbm.iloc[tr_idx], X_train_lgbm.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    model = LGBMRegressor(**lgb_params)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[early_stopping(100), log_evaluation(100)],\n",
    "        categorical_feature=categorical_features_lgbm\n",
    "    )\n",
    "\n",
    "    models_dict['lgbm'].append(model)\n",
    "    val_pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    scores_dict['lgbm'].append((rmse, fold))\n",
    "    preds_dict['lgbm'].append(model.predict(X_test_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8452,
     "status": "ok",
     "timestamp": 1743670563169,
     "user": {
      "displayName": "이승현",
      "userId": "09131068715081423692"
     },
     "user_tz": -540
    },
    "id": "YVcww9g6Ps4a",
    "outputId": "9150fb4c-3719-40f6-a824-0f458733d9b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGBoost-DMatrix] Fold 0\n",
      "[0]\tvalid-rmse:0.42671\n",
      "[100]\tvalid-rmse:0.40117\n",
      "[149]\tvalid-rmse:0.40150\n",
      "[XGBoost-DMatrix] Fold 1\n",
      "[0]\tvalid-rmse:0.42491\n",
      "[100]\tvalid-rmse:0.39995\n",
      "[145]\tvalid-rmse:0.40048\n",
      "[XGBoost-DMatrix] Fold 2\n",
      "[0]\tvalid-rmse:0.42556\n",
      "[100]\tvalid-rmse:0.39970\n",
      "[146]\tvalid-rmse:0.40012\n",
      "[XGBoost-DMatrix] Fold 3\n",
      "[0]\tvalid-rmse:0.42641\n",
      "[100]\tvalid-rmse:0.40147\n",
      "[147]\tvalid-rmse:0.40202\n",
      "[XGBoost-DMatrix] Fold 4\n",
      "[0]\tvalid-rmse:0.42299\n",
      "[100]\tvalid-rmse:0.39854\n",
      "[143]\tvalid-rmse:0.39890\n"
     ]
    }
   ],
   "source": [
    "import xgboost.callback as xcb\n",
    "\n",
    "# XGBoost 학습\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train_xgb)):\n",
    "    print(f\"[XGBoost-DMatrix] Fold {fold}\")\n",
    "    X_tr, X_val = X_train_xgb.iloc[tr_idx], X_train_xgb.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    # DMatrix 변환\n",
    "    dtrain = xgb.DMatrix(X_tr, label=y_tr, enable_categorical=True)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val, enable_categorical=True)\n",
    "    dtest = xgb.DMatrix(X_test_xgb, enable_categorical=True)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params=xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dvalid, 'valid')],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "\n",
    "    models_dict['xgb'].append(model)\n",
    "    val_pred = model.predict(dvalid)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    scores_dict['xgb'].append((rmse, fold))\n",
    "    preds_dict['xgb'].append(model.predict(dtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64452,
     "status": "ok",
     "timestamp": 1743670627639,
     "user": {
      "displayName": "이승현",
      "userId": "09131068715081423692"
     },
     "user_tz": -540
    },
    "id": "DnZJhvLym6nN",
    "outputId": "deaa4356-7be9-4456-ea3c-ba1063f8cecd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CatBoost] Fold 0\n",
      "0:\tlearn: 0.4254104\ttest: 0.4271334\tbest: 0.4271334 (0)\ttotal: 77ms\tremaining: 1m 16s\n",
      "100:\tlearn: 0.3971569\ttest: 0.4006611\tbest: 0.4006603 (99)\ttotal: 2.39s\tremaining: 21.3s\n",
      "200:\tlearn: 0.3952489\ttest: 0.4004456\tbest: 0.4004154 (155)\ttotal: 4.55s\tremaining: 18.1s\n",
      "300:\tlearn: 0.3937154\ttest: 0.4003352\tbest: 0.4003056 (248)\ttotal: 6.05s\tremaining: 14s\n",
      "400:\tlearn: 0.3923397\ttest: 0.4003727\tbest: 0.4002947 (315)\ttotal: 7.5s\tremaining: 11.2s\n",
      "bestTest = 0.4002947289\n",
      "bestIteration = 315\n",
      "Shrink model to first 316 iterations.\n",
      "[CatBoost] Fold 1\n",
      "0:\tlearn: 0.4258433\ttest: 0.4253685\tbest: 0.4253685 (0)\ttotal: 14.2ms\tremaining: 14.2s\n",
      "100:\tlearn: 0.3977101\ttest: 0.3993544\tbest: 0.3993544 (100)\ttotal: 1.56s\tremaining: 13.9s\n",
      "200:\tlearn: 0.3955156\ttest: 0.3989626\tbest: 0.3989600 (198)\ttotal: 3.04s\tremaining: 12.1s\n",
      "300:\tlearn: 0.3938207\ttest: 0.3988972\tbest: 0.3988964 (282)\ttotal: 4.53s\tremaining: 10.5s\n",
      "400:\tlearn: 0.3924485\ttest: 0.3989334\tbest: 0.3988546 (319)\ttotal: 6.03s\tremaining: 9.01s\n",
      "bestTest = 0.3988545546\n",
      "bestIteration = 319\n",
      "Shrink model to first 320 iterations.\n",
      "[CatBoost] Fold 2\n",
      "0:\tlearn: 0.4257102\ttest: 0.4260387\tbest: 0.4260387 (0)\ttotal: 12.4ms\tremaining: 12.3s\n",
      "100:\tlearn: 0.3975222\ttest: 0.3989645\tbest: 0.3989645 (100)\ttotal: 1.44s\tremaining: 12.8s\n",
      "200:\tlearn: 0.3954625\ttest: 0.3986950\tbest: 0.3986678 (151)\ttotal: 2.94s\tremaining: 11.7s\n",
      "bestTest = 0.3986677685\n",
      "bestIteration = 151\n",
      "Shrink model to first 152 iterations.\n",
      "[CatBoost] Fold 3\n",
      "0:\tlearn: 0.4254963\ttest: 0.4268153\tbest: 0.4268153 (0)\ttotal: 13.5ms\tremaining: 13.5s\n",
      "100:\tlearn: 0.3973247\ttest: 0.4004010\tbest: 0.4004010 (100)\ttotal: 1.66s\tremaining: 14.8s\n",
      "200:\tlearn: 0.3952908\ttest: 0.4000575\tbest: 0.4000448 (198)\ttotal: 3.36s\tremaining: 13.4s\n",
      "300:\tlearn: 0.3937666\ttest: 0.3999407\tbest: 0.3999322 (299)\ttotal: 5s\tremaining: 11.6s\n",
      "bestTest = 0.3999321944\n",
      "bestIteration = 299\n",
      "Shrink model to first 300 iterations.\n",
      "[CatBoost] Fold 4\n",
      "0:\tlearn: 0.4262826\ttest: 0.4235059\tbest: 0.4235059 (0)\ttotal: 14ms\tremaining: 14s\n",
      "100:\tlearn: 0.3979561\ttest: 0.3980317\tbest: 0.3980317 (100)\ttotal: 1.47s\tremaining: 13s\n",
      "200:\tlearn: 0.3959419\ttest: 0.3977465\tbest: 0.3977316 (198)\ttotal: 2.92s\tremaining: 11.6s\n",
      "300:\tlearn: 0.3944667\ttest: 0.3976679\tbest: 0.3976519 (299)\ttotal: 4.36s\tremaining: 10.1s\n",
      "bestTest = 0.3976519263\n",
      "bestIteration = 299\n",
      "Shrink model to first 300 iterations.\n"
     ]
    }
   ],
   "source": [
    "# CatBoost 학습\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train_cat)):\n",
    "    print(f\"[CatBoost] Fold {fold}\")\n",
    "    X_tr, X_val = X_train_cat.iloc[tr_idx], X_train_cat.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    train_pool = Pool(X_tr, label=y_tr, cat_features=categorical_features_cat)\n",
    "    val_pool = Pool(X_val, label=y_val, cat_features=categorical_features_cat)\n",
    "\n",
    "    model = CatBoostRegressor(**cat_params)\n",
    "    model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=100, verbose=100)\n",
    "\n",
    "    models_dict['cat'].append(model)\n",
    "    val_pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    scores_dict['cat'].append((rmse, fold))\n",
    "    preds_dict['cat'].append(model.predict(X_test_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsGWQV2sxIIL"
   },
   "source": [
    "## 최종 학습 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm 선택된 fold: [4, 2, 1]\n",
      "xgb 선택된 fold: [4, 2, 1]\n",
      "cat 선택된 fold: [4, 2, 1]\n",
      "파일 저장완료\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "import numpy as np\n",
    "\n",
    "def weighted_rank_ensemble(predictions, weights):\n",
    "    \"\"\"가중 랭크 정규화 평균 앙상블\"\"\"\n",
    "    predictions = np.array(predictions)\n",
    "    ranked_preds = np.array([rankdata(pred) for pred in predictions])\n",
    "    weighted_avg_rank = np.average(ranked_preds, axis=0, weights=weights)\n",
    "    return weighted_avg_rank / np.max(weighted_avg_rank)  # 정규화\n",
    "\n",
    "# 각 모델에 대한 가중치 수동 설정\n",
    "manual_weights = {\n",
    "    'lgbm': 1.5,\n",
    "    'xgb': 3.0,\n",
    "    'cat': 2.9\n",
    "}\n",
    "\n",
    "# 모델당 상위 N개 unique fold만 사용\n",
    "n = 3  # top-N fold 선택\n",
    "selected_preds = []\n",
    "selected_weights = []\n",
    "\n",
    "for model_name in ['lgbm', 'xgb', 'cat']:\n",
    "    # RMSE 기준 오름차순 정렬\n",
    "    folds = sorted(scores_dict[model_name], key=lambda x: x[0])\n",
    "    unique_fold_idxs = []\n",
    "    for rmse, fold in folds:\n",
    "        if fold not in unique_fold_idxs:\n",
    "            unique_fold_idxs.append(fold)\n",
    "        if len(unique_fold_idxs) == n:\n",
    "            break\n",
    "    print(f\"{model_name} 선택된 fold: {unique_fold_idxs}\")\n",
    "    \n",
    "    for fold_idx in unique_fold_idxs:\n",
    "        selected_preds.append(preds_dict[model_name][fold_idx])\n",
    "        selected_weights.append(manual_weights[model_name])\n",
    "\n",
    "# 최종 앙상블 결과 생성\n",
    "final_preds = weighted_rank_ensemble(selected_preds, selected_weights)\n",
    "\n",
    "# 0.3~0.7 사이에 몰려있는 확률 → 약간 더 극단적으로 밀기\n",
    "clip_final_preds = np.clip(0.89 * final_preds + 0.003, 0, 1)\n",
    "\n",
    "submission_df['ID'] = test_ids \n",
    "submission_df['임신 성공 확률'] = clip_final_preds\n",
    "\n",
    "file_name = f'new_top{n}_per_model.csv'\n",
    "submission_df.to_csv(file_name, index=False)\n",
    "print('파일 저장완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPtE2AFM5+WLrXwNjPy0Af+",
   "collapsed_sections": [
    "pFb6DCy8Accg",
    "1NC0bYFBtWL8",
    "gbaYqDtfTDSf",
    "Yc9yFNDclK9K",
    "Gw0lDqn8vMVr",
    "XqCaMRG-Lwqd",
    "wH-MYX8HDbUv"
   ],
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
